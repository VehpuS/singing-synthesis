<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>OddVoices Comparisons</title>
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <article id="blurb">
      <h2>About OddVoices</h2>

      <p>OddVoices is a free and open source singing synthesizer for American English. Rather than aiming for natural or perfect singing, OddVoices intends to tap into the wonderful, weird, and not-quite-human qualities of speech synthesizers from the 80's and 90's. It's not an emulation of any particular vintage voice, but an entirely new project from scratch.</p>

      <h2>Why OddVoices?</h2>

      <p>There's no such thing as a bad vocal synthesizer -- if something sounds like the human voice, then someone out there can find an artistic use for it. However, OddVoices was created to fill a specific need. No other singing synthesizer currently ticks all the following boxes:</p>

      <ul>
        <li>All code and vocal data is available under free licenses (Apache and CC0, respectively).</li>
        <li>The vocal data is specifically by trained singers, not just generic speakers. The vocal data was created specifically for OddVoices; it's not an existing speech synthesizer that's been forced to sing.</li>
        <li>The project provides both high-level and low-level APIs depending on your needs. Developers can exert fine-grained control of synthesis parameters and phonemes using the C++ API or a JSON file format, but you can also just plug in MIDI and English text if you want a simple frontend.</li>
        <li>It's built with real time synthesis in mind.</li>
      </ul>

      <p>If you care about the engineering side of things, the OddVoices codebase is compact and simple both in algorithms and engineering at a total of 2,000 LOC. The core C++ synthesizer depends only on the standard library, with an optional MIDI frontend that depends on the midifile library. The analysis code for creating new voices is written in Python and depends on NumPy, SciPy, and PySoundFile. The primary motivation for the minimalism is software longevity -- bitrot is inevitable but less likely to be a problem if the project is small and the dependencies are few.</p>

      <p>Finally, OddVoices is an "indie" singing synthesizer: it's a one-person passion project, and not at the whims of any corporate or academic organization. Passion projects can have their logistical problems, but you at least don't have to worry about abandonment due to commercial unprofitability or someone finishing their degree.</p>

      <h2>Why not OddVoices?</h2>

      <p><em>Intelligilibity</em> is the biggest issue with OddVoices right now. It can be really hard to tell what the voice is saying. Improving this area is a big priority of the project, but for now if you need crystal clear lyrics, then look elsewhere.</p>

      <p><em>Naturalness:</em> sounding exactly like a human singer is an explicit non-goal of OddVoices. It's a tool for artists who want something strange and off-kilter. Still, to a reasonable extent naturalness is desirable.</p>

      <p><em>Language support:</em> OddVoices is built specifically for English. I'm not fluent in any other languages, and adding another language will require close collaboration with a native speaker with linguistics knowledge. This isn't on the roadmap unless a qualified person can step up and volunteer to have their language supported.</p>

      <h2>Future project directions</h2>

      <ul>
        <li>Research ways to improve intelligibility and naturalness.</li>
        <li>Add speech and rapping support.</li>
        <li>Develop a Web-based piano roll editor with integrated lyric support.</li>
        <li>Develop a VST or CLAP plugin. This is a huge project but a necessary one for an optimal workflow. The need for an in-plugin piano roll editor is mandated by OddVoices' requirement to peek ahead to anticipate the end of a syllable.</li>
      </ul>

      <h2>Comparisons to other free or open source projects</h2>

      <p>Making a synthesizer capable of speaking or singing text (and not just vowels) is an intense and challenging project.</p>

      <p><em>eSpeak</em> is a very mature Klatt-style formant speech synthesizer that supports a huge number of languages. It is a full TTS system with textual input. It suffers under the typical burdens of a legacy codebase from the 90's, with a lot of serious feature creep and a rather baroque developer API. I found two singing frontends for eSpeak: eCantorix and meSing. Both take a crude approach of repitching the output of eSpeak, and major musical limitations result in both cases.</p>

      <p><em>MBROLA</em> is a diphone speech synthesizer of the same class as OddVoices. While the code itself is GPL, the vocal data isn't under a free or open source license. It is a backend only: the input format is a text file containing phoneme, pitch, and timing data. There is a cap on how much time-stretching can be done, which makes it impossible to sing sustained tones and severely hinders the musical possibilities.</p>

      <p><em>Sinsy</em> and <em>MAGE</em> are both based on the HTS engine for Hidden Markov Model-based speech synthesis. They achieve some realistic results, but .</p>

      <p><em>rsynth</em> is a very compact English formant speech synthesizer, and likely one of the only public domain speech synthesizers. It is a full TTS system with a crude rule-based pronunciation frontend. Its author sadly passed away and the original repo has undergone bitrot, but various forks of it have been circulated around, most notably in the SoLoud audio library and a header-only version.</p>

      <p><em>OpenUTAU</em> is a successor to the UTAU project. It's quite different from other synthesizers on this list because, like the UTAU project that it succeeds, it's a graphical interface for manually selecting, sequencing, and transforming samples of syllables, and it's built specifically for singing. It is comparable to some commercial singing synthesizers but requires more manual work. OddVoices is fully automated in sample selection, but it lacks a lot of the tuning capabilities that OpenUTAU has.</p>

      <p>There are also many recent voice synthesis projects based on deep learning, and many of them achieve extremely realistic results. Most of them require massive datasets, complex algorithms, and huge amounts of compute time, although I expect these disadvantages to be addressed over time. More fundamentally, such synthesizers have different goals than I do, because I'm much more fascinated by transparently artificial voices built on simple technology.</p>
    </article>
  </body>
</html>
